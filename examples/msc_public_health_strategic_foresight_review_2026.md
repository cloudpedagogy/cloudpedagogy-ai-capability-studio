# AI Workflow Record

**Project:** MSc Public Health — Strategic Foresight Review (2026)
**Status:** completed
**Updated:** 2026-02-15T23:41:02.079Z
**App version:** 0.1.1

## Exercise
- **Title:** Apply the AI Capability Framework — Scenario Planning and Environmental Scanning (Ch03)
- **Template:** structured_workflow
- **Exercise version:** 1.0
- **Source:** Bundled
- **Tags:** bundle:ai-capability-framework, type:fw, framework:apply, course:genai-in-strategic-decision-making-and-institutional-intelligence, chapter:ch03, topic:foresight

## Workflow
Move from sensing change to making sense, rehearsing futures, testing vulnerabilities, and translating insights into accountable operational decisions using structured human–AI collaboration.

## Inputs
- **context_type:** institutional_strategy
- **field_area:** Higher Education Strategy (Public Health and Global Health Systems)
- **level_scope:** institution_level
- **notes_priorities:** Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
- **source_material:** Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

## Steps
### AI orientation note for your foresight set-up

**Instructions:**
- Map where AI currently supports scanning, trend analysis, scenario work, or stress-testing in your context.
- State assumptions about sources, language, geography, and sector focus that may shape what the model notices.
- Identify likely blind spots and missing voices, including marginalised learner and staff perspectives.
- Draft an orientation note with strengths, red lines, and a short health warning to attach to AI-generated briefs.

**Values in play:** transparency, humility, stewardship, inclusion

**Reflection prompts:**
- What do leaders currently believe the model is doing, and where might that mental model be inaccurate?
- How could misread confidence in AI summaries distort perceived urgency, risk, or opportunity?

**Responses:**
- **Current or planned AI uses in foresight:**
Environmental scanning of policy documents, sector reports, and relevant public guidance

Trend clustering and thematic synthesis across multiple sources

Drafting alternative scenario narratives (plausible futures)

Identifying potential operational stress points (e.g., regulatory change, funding volatility, technology shifts)

Generating structured briefing notes for senior leadership discussion

- **Assumptions and blind spots:**
AI outputs over-represent dominant English-language and highly indexed sources

Regional coverage is uneven, with less visibility of Global South signals and local scholarship

AI synthesis can reflect frequency/visibility rather than importance/impact

Tacit institutional knowledge and informal intelligence are not captured unless explicitly added

Institutional documents are assumed current and internally consistent

- **Orientation note requirements:**
Plain language suitable for senior leadership

Clear distinction between drafting/support and decision-making/accountability

Explicit strengths and limitations, grounded in the institutional context

Clear red lines (what is not permitted)

Confidence guidance (how to interpret certainty and evidence quality)

Equity, accessibility, and representation considerations included

A reusable 2–3 sentence “health warning” to attach to every AI-generated brief

No claims of predictive certainty

**Prompt used (rendered):**
You are supporting the creation of an AI Orientation Note for an AI-augmented institutional foresight workflow (environmental scanning → trends → scenarios → stress-testing → operational translation).

Context type: institutional_strategy
Field/discipline: Higher Education Strategy (Public Health and Global Health Systems)
Level/scope: institution_level
Priorities: Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
Source material: Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

Current AI uses:
Environmental scanning of policy documents, sector reports, and relevant public guidance

Trend clustering and thematic synthesis across multiple sources

Drafting alternative scenario narratives (plausible futures)

Identifying potential operational stress points (e.g., regulatory change, funding volatility, technology shifts)

Generating structured briefing notes for senior leadership discussion

Assumptions and blind spots:
AI outputs over-represent dominant English-language and highly indexed sources

Regional coverage is uneven, with less visibility of Global South signals and local scholarship

AI synthesis can reflect frequency/visibility rather than importance/impact

Tacit institutional knowledge and informal intelligence are not captured unless explicitly added

Institutional documents are assumed current and internally consistent

Orientation note requirements:
Plain language suitable for senior leadership

Clear distinction between drafting/support and decision-making/accountability

Explicit strengths and limitations, grounded in the institutional context

Clear red lines (what is not permitted)

Confidence guidance (how to interpret certainty and evidence quality)

Equity, accessibility, and representation considerations included

A reusable 2–3 sentence “health warning” to attach to every AI-generated brief

No claims of predictive certainty

Task:
1) Summarise what the AI system is (and is not) doing in this foresight workflow, in plain language suitable for senior leadership.
2) List key strengths and key limitations grounded in the provided context (include at least 2 concrete examples of “what it can help with” and “where it can mislead”).
3) Identify likely missing signals/voices and why (include at least one example relevant to equity, accessibility, Global South perspectives, or non-dominant disciplines).
4) Produce a one-page AI Orientation Note with: (a) purpose; (b) allowed use cases; (c) red lines; (d) confidence guidance; (e) a 2–3 sentence “health warning” to attach to every AI-generated brief.

Treat outputs as draft options for human review.

Return using headings:
A) Draft Output
B) Assumptions
C) Risks / Uncertainties (at least 3)
D) Validation Checks (at least 3)
E) Questions for Human Review


### Co-agency charter for scenario and simulation work

**Instructions:**
- Define what AI is responsible for in your foresight workflow and what must remain human-led judgement.
- Specify review roles, escalation paths, and how disagreements between AI output and human judgement are handled.
- Create collaboration patterns for at least two settings relevant to your context (e.g., executive retreat, faculty workshop).
- Record accountability statements that make ownership of decisions explicit.

**Values in play:** collaboration, agency, role_clarity, accountability

**Reflection prompts:**
- Where might AI be overstepping into decisions that should remain human?
- Where are humans doing repetitive synthesis that could be safely delegated to AI?

**Responses:**
- **What AI is responsible for:**
Synthesising environmental scan materials across institutional and sector sources

Clustering and summarising emerging trends

Drafting alternative scenario narratives (multiple plausible futures)

Identifying potential operational stress points under each scenario

Generating structured briefing notes for leadership discussion

Highlighting inconsistencies between trends and stated strategic priorities

- **What humans are responsible for:**
Defining institutional values, risk appetite, and strategic priorities

Evaluating plausibility, desirability, and political feasibility of scenarios

Reviewing equity, accessibility, and Global South representation risks

Determining which scenarios merit operational action

Approving translation into policy, investment, or programme change

Documenting final decisions and accountability statements

- **Collaboration patterns to design:**
Executive retreat: AI drafts multi-scenario briefing pack; leadership interrogates assumptions and records decisions.

Faculty foresight workshop: AI clusters workshop inputs; participants validate, contest, and contextualise interpretations.

Governance committee review: AI-informed stress-testing outputs reviewed against institutional strategy before approval or escalation.

**Prompt used (rendered):**
You are supporting the design of a Co-Agency Charter that clarifies human vs AI roles in scenario planning, simulation, and synthesis within an institutional foresight cycle.

Context type: institutional_strategy
Field/discipline: Higher Education Strategy (Public Health and Global Health Systems)
Level/scope: institution_level
Priorities: Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
Source material: Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

AI responsibilities:
Synthesising environmental scan materials across institutional and sector sources

Clustering and summarising emerging trends

Drafting alternative scenario narratives (multiple plausible futures)

Identifying potential operational stress points under each scenario

Generating structured briefing notes for leadership discussion

Highlighting inconsistencies between trends and stated strategic priorities

Human responsibilities:
Defining institutional values, risk appetite, and strategic priorities

Evaluating plausibility, desirability, and political feasibility of scenarios

Reviewing equity, accessibility, and Global South representation risks

Determining which scenarios merit operational action

Approving translation into policy, investment, or programme change

Documenting final decisions and accountability statements

Collaboration patterns to design:
Executive retreat: AI drafts multi-scenario briefing pack; leadership interrogates assumptions and records decisions.

Faculty foresight workshop: AI clusters workshop inputs; participants validate, contest, and contextualise interpretations.

Governance committee review: AI-informed stress-testing outputs reviewed against institutional strategy before approval or escalation.

Task:
1) Draft a Co-Agency Charter with clear role boundaries: what AI may draft, what humans must decide, and what requires joint review.
2) Define review checkpoints (who reviews, when, and what criteria trigger revision or rejection), with at least 2 context-specific examples.
3) Specify a disagreement protocol: how to handle conflicts between AI outputs and human judgement (include escalation and documentation).
4) Produce 2–3 collaboration patterns (e.g., executive retreat, faculty foresight workshop, operational risk meeting) showing when AI is used, who reviews outputs, and how decisions are recorded.

Treat outputs as draft options for human review.

Return using headings:
A) Draft Output
B) Assumptions
C) Risks / Uncertainties (at least 3)
D) Validation Checks (at least 3)
E) Questions for Human Review


### Prototype an AI-enabled scanning and trend workflow

**Instructions:**
- Sketch a minimal viable workflow for scanning and trend analysis including sources, prompts, review points, and output cadence.
- Generate 3–4 scanning lenses tailored to your context and produce contrasting brief variants per lens.
- Select one micro-innovation to pilot and define success criteria, ownership, and retirement triggers.
- Ensure the prototype is realistic for busy institutional conditions and aligned with local governance.

**Values in play:** creative_risk_taking, proportionality, inclusion, learning_by_doing

**Reflection prompts:**
- How can AI-enabled scanning avoid becoming glossy output without operational follow-through?
- Which experiments are safe to run immediately, and which require formal approval?

**Responses:**
- **Candidate sources and signals:**
External policy and sector signals

WHO, UN SDG updates, global health policy briefings (detect global regulatory shifts and funding priorities)

UK government education and research policy portals (detect compliance or funding changes)

OECD and World Bank education outlooks (detect macro trends in international higher education)

Major funders (Wellcome Trust, NIHR, Gates Foundation) announcements (detect priority reorientation)

Sector and professional signals

Higher education trade press (Times Higher, Wonkhe) for regulatory and sector narrative shifts

Public health professional bodies and networks for disciplinary debates

AI governance updates (UK, EU AI Act developments)

Internal institutional signals

Student feedback themes (detect dissatisfaction, emerging expectations)

NSS / PTES data trends

Programme review outcomes

Research grant success patterns

What we aim to detect

Emerging risks to programme sustainability

Shifts in global public health priorities

Technology adoption inflection points

Reputational exposure signals

Equity and accessibility risks

- **Workflow constraints and review points:**
Cadence

Monthly AI-assisted scan

Quarterly synthesis briefing to Faculty strategy group

Review structure

Initial AI synthesis reviewed by Foresight Lead

Equity and Global South lens check by designated reviewer

Escalation to Faculty Executive if high-impact risk identified

Risk tolerance

Low tolerance for regulatory blind spots

Moderate tolerance for exploratory scenario drafting

Tools

AI-assisted clustering (LLM-based)

Structured Markdown brief template

Shared governance log for documenting revisions

Trigger for escalation

Conflicts with Education Strategy 2025–27

Significant budget or staffing implications

Major reputational exposure

- **Micro-innovation to pilot:**
Pilot: “Fortnightly Trend Pulse”

A concise two-page AI-assisted scanning brief circulated to Faculty leadership every two weeks.

Structure

Top 3 emerging signals

1 plausible implication for programmes

1 potential risk

1 opportunity

Success criteria

Leadership engagement (feedback within 48 hours)

At least one trend escalated into formal discussion per quarter

Evidence of early identification of regulatory or funding shifts

Ownership

Foresight Lead (content oversight)

Faculty Strategy Manager (distribution and governance logging)

Retirement trigger

No actionable insights generated over 3 consecutive cycles

Review group identifies duplication with existing reporting

**Prompt used (rendered):**
You are supporting the prototyping of an AI-enabled environmental scanning and trend analysis workflow that is small enough to pilot but robust enough for governance use.

Context type: institutional_strategy
Field/discipline: Higher Education Strategy (Public Health and Global Health Systems)
Level/scope: institution_level
Priorities: Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
Source material: Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

Candidate sources and signals:
External policy and sector signals

WHO, UN SDG updates, global health policy briefings (detect global regulatory shifts and funding priorities)

UK government education and research policy portals (detect compliance or funding changes)

OECD and World Bank education outlooks (detect macro trends in international higher education)

Major funders (Wellcome Trust, NIHR, Gates Foundation) announcements (detect priority reorientation)

Sector and professional signals

Higher education trade press (Times Higher, Wonkhe) for regulatory and sector narrative shifts

Public health professional bodies and networks for disciplinary debates

AI governance updates (UK, EU AI Act developments)

Internal institutional signals

Student feedback themes (detect dissatisfaction, emerging expectations)

NSS / PTES data trends

Programme review outcomes

Research grant success patterns

What we aim to detect

Emerging risks to programme sustainability

Shifts in global public health priorities

Technology adoption inflection points

Reputational exposure signals

Equity and accessibility risks

Workflow constraints and review points:
Cadence

Monthly AI-assisted scan

Quarterly synthesis briefing to Faculty strategy group

Review structure

Initial AI synthesis reviewed by Foresight Lead

Equity and Global South lens check by designated reviewer

Escalation to Faculty Executive if high-impact risk identified

Risk tolerance

Low tolerance for regulatory blind spots

Moderate tolerance for exploratory scenario drafting

Tools

AI-assisted clustering (LLM-based)

Structured Markdown brief template

Shared governance log for documenting revisions

Trigger for escalation

Conflicts with Education Strategy 2025–27

Significant budget or staffing implications

Major reputational exposure

Micro-innovation to pilot:
Pilot: “Fortnightly Trend Pulse”

A concise two-page AI-assisted scanning brief circulated to Faculty leadership every two weeks.

Structure

Top 3 emerging signals

1 plausible implication for programmes

1 potential risk

1 opportunity

Success criteria

Leadership engagement (feedback within 48 hours)

At least one trend escalated into formal discussion per quarter

Evidence of early identification of regulatory or funding shifts

Ownership

Foresight Lead (content oversight)

Faculty Strategy Manager (distribution and governance logging)

Retirement trigger

No actionable insights generated over 3 consecutive cycles

Review group identifies duplication with existing reporting

Task:
1) Propose a minimal viable workflow (inputs → processing → review → outputs) including sources, prompt strategy, review checkpoints, and output cadence.
2) Propose 3–4 novel scanning lenses tailored to this context, and for each lens generate three brief variants (optimistic, pessimistic, equity-focused) with at least 2 context-specific examples of implications.
3) Recommend one micro-innovation to pilot, including ownership, success criteria, and a “stop/retire” trigger if outputs are misleading or harmful.
4) List practical constraints and mitigations (time, capability, governance) to keep the prototype realistic.

Treat outputs as draft options for human review.

Return using headings:
A) Draft Output
B) Assumptions
C) Risks / Uncertainties (at least 3)
D) Validation Checks (at least 3)
E) Questions for Human Review


### Ethical futures audit of scenarios and simulations

**Instructions:**
- Select one scenario output and identify who is explicit, implicit, and absent across learners, staff, partners, and regions.
- Generate an equity-anchored variant that centres a minoritised group or justice perspective.
- Compare strategic conclusions that follow from the original and the equity-anchored variant.
- Define a repeatable rule for ensuring every scenario pack includes at least one equity-anchored variant.

**Values in play:** equity, justice, accessibility, epistemic_plurality

**Reflection prompts:**
- What harms arise when leadership only sees futures centred on dominant groups or well-resourced institutions?
- How could you institutionalise equity-anchored variants as a non-optional practice?

**Responses:**
- **Scenario to audit:**
Scenario: “AI-Accelerated Global Health Institution” (2030)
The institution rapidly adopts AI-supported teaching, automated assessment feedback, predictive enrolment modelling, and AI-assisted research synthesis. International student recruitment grows through digital delivery models. Operational efficiency improves through automation of routine administrative processes. Strategic investment shifts toward AI capability development and industry partnerships in digital health.

Key assumptions:

Staff adapt quickly to AI-supported workflows.

Students have adequate digital access.

AI tools are reliable and compliant with regulatory standards.

Global demand for digitally delivered public health education continues to grow.

- **Who is missing or marginalised:**
Disabled learners requiring accessible design beyond basic captioning

Students in low-bandwidth Global South contexts

Carers and mature learners balancing study and employment

Academic staff in non-technical disciplines

Local public health practitioners without strong digital infrastructure

Community partners outside OECD countries

Disciplines that resist techno-solutionist framing

Implicitly centred group:

Digitally confident, well-resourced, Global North learners

Technically adaptable academic staff

Institutions with strong IT infrastructure

- **Equity focus for the alternative scenario:**
Equity focus: Global South and low-bandwidth public health institutions

Alternative scenario lens:

Re-imagine 2030 where AI adoption must operate under:

Intermittent connectivity

Limited computing access

Regulatory environments with lower AI governance capacity

Public health priorities driven by local disease burden rather than global funding agendas

This equity-anchored variant centres:

Infrastructure constraints

Linguistic diversity

Decolonial knowledge production

Capacity-building partnerships rather than extractive collaboration

**Prompt used (rendered):**
You are supporting an Ethical Futures Audit of AI-generated scenarios to identify bias, blind spots, and equity impacts.

Context type: institutional_strategy
Field/discipline: Higher Education Strategy (Public Health and Global Health Systems)
Level/scope: institution_level
Priorities: Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
Source material: Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

Scenario to audit:
Scenario: “AI-Accelerated Global Health Institution” (2030)
The institution rapidly adopts AI-supported teaching, automated assessment feedback, predictive enrolment modelling, and AI-assisted research synthesis. International student recruitment grows through digital delivery models. Operational efficiency improves through automation of routine administrative processes. Strategic investment shifts toward AI capability development and industry partnerships in digital health.

Key assumptions:

Staff adapt quickly to AI-supported workflows.

Students have adequate digital access.

AI tools are reliable and compliant with regulatory standards.

Global demand for digitally delivered public health education continues to grow.

Who is missing or marginalised:
Disabled learners requiring accessible design beyond basic captioning

Students in low-bandwidth Global South contexts

Carers and mature learners balancing study and employment

Academic staff in non-technical disciplines

Local public health practitioners without strong digital infrastructure

Community partners outside OECD countries

Disciplines that resist techno-solutionist framing

Implicitly centred group:

Digitally confident, well-resourced, Global North learners

Technically adaptable academic staff

Institutions with strong IT infrastructure

Equity focus for the alternative scenario:
Equity focus: Global South and low-bandwidth public health institutions

Alternative scenario lens:

Re-imagine 2030 where AI adoption must operate under:

Intermittent connectivity

Limited computing access

Regulatory environments with lower AI governance capacity

Public health priorities driven by local disease burden rather than global funding agendas

This equity-anchored variant centres:

Infrastructure constraints

Linguistic diversity

Decolonial knowledge production

Capacity-building partnerships rather than extractive collaboration

Task:
1) Audit the scenario by identifying who appears explicitly, implicitly, and who is absent; include at least 2 context-specific examples of how absence could distort decisions.
2) Generate an alternative version of the same scenario that centres the specified equity focus (or propose a suitable equity focus if not provided).
3) Compare the original and equity-anchored scenarios and list 3 ways strategic conclusions, risks, or priorities might differ.
4) Propose a simple, repeatable institutional rule for equity-anchored variants (e.g., “every scenario pack must include one equity variant + one Global South variant”) and how it would be checked.

Treat outputs as draft options for human review.

Return using headings:
A) Draft Output
B) Assumptions
C) Risks / Uncertainties (at least 3)
D) Validation Checks (at least 3)
E) Questions for Human Review


### Governance design for AI-supported foresight decisions

**Instructions:**
- Map one decision pathway where AI informs scanning, trends, scenarios, stress-testing, and operational planning.
- Define where AI is used, who can override outputs, and what documentation is mandatory at each stage.
- Draft a foresight decision log template capturing options tested, equity implications, and final justification.
- Identify who gains influence through AI-supported foresight and design participation checks to reduce marginalisation.

**Values in play:** transparency, accountability, participation, stewardship

**Reflection prompts:**
- Who gains influence from AI-supported foresight in your current structures, and who risks being sidelined?
- How can transparent logs and participatory review reduce the risk of 'AI-washed' decisions?

**Responses:**
- **Decision question to map:**
Decision: Whether to invest in an AI-enabled institutional foresight and scenario planning system to inform the next Education Strategy (2028–2032).

This includes decisions about:

Resourcing AI-supported environmental scanning

Embedding structured scenario planning in annual planning cycles

Introducing AI-assisted stress-testing of major strategic initiatives

Allocating budget and staff time to AI literacy and governance capacity

The decision has financial, reputational, governance, and equity implications.

- **Foresight stages involved:**
Environmental Scanning (Quarterly)
AI use:

Aggregate sector reports, policy briefings, and trend summaries

Cluster emerging themes (e.g., regulation, funding volatility, AI governance shifts)
Human roles:

Foresight lead reviews source diversity

Faculty representatives validate contextual relevance

Equity reviewer checks geographic and disciplinary representation

Trend Synthesis (Biannual)
AI use:

Draft structured trend briefs

Identify cross-cutting risks and opportunities
Human roles:

Strategy committee reviews plausibility

Equity and inclusion representative checks for marginalised perspectives

Scenario Development (Annual Retreat)
AI use:

Draft 3–4 contrasting scenario narratives

Stress-test strategic assumptions
Human roles:

Executive team challenge assumptions

Faculty leaders assess academic feasibility

Governance representative checks alignment with Education Strategy

Stress-Testing (Pre-Approval Stage)
AI use:

Simulate impact of scenarios on finances, staffing, student demand
Human roles:

Finance director validates affordability

Quality assurance lead checks regulatory compliance

Ethics/governance lead assesses reputational and equity risks

Operational Translation (Post-Decision)
AI use:

Draft implementation roadmap variants
Human roles:

Executive board approves final direction

Decision rationale documented in committee minutes

- **Governance constraints:**
Formal approval required by Education Committee and Council for major strategic investments

Alignment with Education Strategy 2025–27 mandatory

Documentation must meet audit and quality assurance standards

Equity impact statement required for strategic changes

AI-generated materials must be clearly marked as draft advisory outputs

Human decision authority must be explicitly recorded

Model transparency expectations: source traceability, no fabricated citations, no automated decision-making

Additional constraints:

Decisions must be defensible under sector AI governance guidance

Budget thresholds above agreed tolerance require Council approval

Any major workforce implication requires consultation under institutional HR policy

**Prompt used (rendered):**
You are supporting the design of a governance pattern for AI-supported institutional foresight that traces how AI outputs influence decisions and documents accountability.

Context type: institutional_strategy
Field/discipline: Higher Education Strategy (Public Health and Global Health Systems)
Level/scope: institution_level
Priorities: Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
Source material: Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

Decision question to map:
Decision: Whether to invest in an AI-enabled institutional foresight and scenario planning system to inform the next Education Strategy (2028–2032).

This includes decisions about:

Resourcing AI-supported environmental scanning

Embedding structured scenario planning in annual planning cycles

Introducing AI-assisted stress-testing of major strategic initiatives

Allocating budget and staff time to AI literacy and governance capacity

The decision has financial, reputational, governance, and equity implications.

Foresight stages involved:
Environmental Scanning (Quarterly)
AI use:

Aggregate sector reports, policy briefings, and trend summaries

Cluster emerging themes (e.g., regulation, funding volatility, AI governance shifts)
Human roles:

Foresight lead reviews source diversity

Faculty representatives validate contextual relevance

Equity reviewer checks geographic and disciplinary representation

Trend Synthesis (Biannual)
AI use:

Draft structured trend briefs

Identify cross-cutting risks and opportunities
Human roles:

Strategy committee reviews plausibility

Equity and inclusion representative checks for marginalised perspectives

Scenario Development (Annual Retreat)
AI use:

Draft 3–4 contrasting scenario narratives

Stress-test strategic assumptions
Human roles:

Executive team challenge assumptions

Faculty leaders assess academic feasibility

Governance representative checks alignment with Education Strategy

Stress-Testing (Pre-Approval Stage)
AI use:

Simulate impact of scenarios on finances, staffing, student demand
Human roles:

Finance director validates affordability

Quality assurance lead checks regulatory compliance

Ethics/governance lead assesses reputational and equity risks

Operational Translation (Post-Decision)
AI use:

Draft implementation roadmap variants
Human roles:

Executive board approves final direction

Decision rationale documented in committee minutes

Governance constraints:
Formal approval required by Education Committee and Council for major strategic investments

Alignment with Education Strategy 2025–27 mandatory

Documentation must meet audit and quality assurance standards

Equity impact statement required for strategic changes

AI-generated materials must be clearly marked as draft advisory outputs

Human decision authority must be explicitly recorded

Model transparency expectations: source traceability, no fabricated citations, no automated decision-making

Additional constraints:

Decisions must be defensible under sector AI governance guidance

Budget thresholds above agreed tolerance require Council approval

Any major workforce implication requires consultation under institutional HR policy

Task:
1) Map a decision pathway across scanning, trend analysis, scenario building, stress-testing, and operational translation; describe where AI is used at each stage.
2) For each stage, specify: (a) who has the right to question/override; (b) what must be documented (prompts, data sources, assumptions, human decisions); include at least 2 context-specific examples.
3) Draft a “Foresight Decision Log” template with fields for options tested, futures/scenarios considered, equity implications, and final justification.
4) Identify participation risks (who is marginalised) and propose safeguards (e.g., cross-unit review, student/community voice, equity gate).

Treat outputs as draft options for human review.

Return using headings:
A) Draft Output
B) Assumptions
C) Risks / Uncertainties (at least 3)
D) Validation Checks (at least 3)
E) Questions for Human Review


### Foresight learning log and capability renewal

**Instructions:**
- Reconstruct 2–3 foresight activities and record assumptions, decisions, and what actually happened over time.
- Identify what was overestimated or underestimated and how AI tools helped or hindered sense-making.
- Extract repeatable design principles for future foresight work including scheduled updates and equity checks.
- Write an AI use statement suitable for governance documentation and future audit trails.

**Values in play:** learning, humility, renewal, continuity

**Reflection prompts:**
- If you looked back in five years, what would you want recorded about how AI shaped foresight today?
- How can foresight become cumulative capability rather than disconnected projects?

**Responses:**
- **Past or current foresight activities to log:**
COVID-era teaching and delivery scenarios (2020–2022)

Rapid pivot to online and hybrid delivery

Assumptions about long-term digital adoption

Scenario planning around international student mobility

AI in assessment and curriculum futures review (2023–2025)

Scenarios on generative AI impact on assessment integrity

Exploration of AI literacy embedding in postgraduate programmes

Stress-testing regulatory and reputational risks

Digital resilience and infrastructure stress-test (2024–2025)

Scenario modelling of platform outages, cyber incidents, and regulatory AI shifts

Environmental scanning of sector AI governance developments

Financial and staffing vulnerability analysis

- **Capability map / renewal summary:**
Capability Improvements Across Six Domains

AI Awareness & Orientation

Increased leadership literacy regarding AI capabilities and limitations

Clearer understanding of AI as advisory rather than decision-making

Human–AI Co-Agency

Structured separation of drafting (AI) and judgement (human)

Improved documentation of override decisions and escalation pathways

Applied Practice & Innovation

Introduction of scenario rehearsal and stress-testing techniques

Pilot use of AI-assisted environmental scanning and structured brief generation

Ethics, Equity & Impact

Stronger emphasis on Global South representation in scenario development

Inclusion of explicit equity-anchored scenario variants

Decision-Making & Governance

Clearer checkpoints in committee cycles

More transparent decision logs recording AI advisory input

Reflection, Learning & Renewal

Shift from one-off foresight exercises to repeatable annual cycles

Creation of documented foresight learning logs for audit and renewal

Renewal Priorities (Next 12–24 Months)

Formalise quarterly scanning cadence

Embed mandatory equity variant in all scenario packs

Introduce structured capability review every academic year

Develop staff development on AI-supported strategic synthesis

Reduce over-reliance on polished AI summaries without deep interrogation

- **AI use statement (for governance):**
Artificial intelligence tools were used to support structured environmental scanning, trend clustering, and first-draft scenario development within the institutional foresight cycle. All AI outputs were treated as advisory drafts and subject to documented human review, challenge, and revision prior to any strategic decision. Human decision-makers retained full authority over interpretation, prioritisation, and approval. AI contributions were transparently recorded to support auditability and governance oversight.

**Prompt used (rendered):**
You are supporting a Foresight Learning Log that turns repeated scanning/scenario activities into cumulative organisational learning and a governance-ready capability record.

Context type: institutional_strategy
Field/discipline: Higher Education Strategy (Public Health and Global Health Systems)
Level/scope: institution_level
Priorities: Embed AI literacy; strengthen structured scenario planning; reduce strategic blind spots; ensure equity and Global South representation; align foresight outputs with institutional governance processes; support evidence-informed decision-making.
Source material: Institutional Education Strategy 2025–27; Faculty strategic plan; student feedback reports; global higher education trend analyses; WHO and UN SDG policy briefings; sector AI governance guidance; environmental scanning summaries.

Past or current foresight activities to log:
COVID-era teaching and delivery scenarios (2020–2022)

Rapid pivot to online and hybrid delivery

Assumptions about long-term digital adoption

Scenario planning around international student mobility

AI in assessment and curriculum futures review (2023–2025)

Scenarios on generative AI impact on assessment integrity

Exploration of AI literacy embedding in postgraduate programmes

Stress-testing regulatory and reputational risks

Digital resilience and infrastructure stress-test (2024–2025)

Scenario modelling of platform outages, cyber incidents, and regulatory AI shifts

Environmental scanning of sector AI governance developments

Financial and staffing vulnerability analysis

Capability map / renewal summary:
Capability Improvements Across Six Domains

AI Awareness & Orientation

Increased leadership literacy regarding AI capabilities and limitations

Clearer understanding of AI as advisory rather than decision-making

Human–AI Co-Agency

Structured separation of drafting (AI) and judgement (human)

Improved documentation of override decisions and escalation pathways

Applied Practice & Innovation

Introduction of scenario rehearsal and stress-testing techniques

Pilot use of AI-assisted environmental scanning and structured brief generation

Ethics, Equity & Impact

Stronger emphasis on Global South representation in scenario development

Inclusion of explicit equity-anchored scenario variants

Decision-Making & Governance

Clearer checkpoints in committee cycles

More transparent decision logs recording AI advisory input

Reflection, Learning & Renewal

Shift from one-off foresight exercises to repeatable annual cycles

Creation of documented foresight learning logs for audit and renewal

Renewal Priorities (Next 12–24 Months)

Formalise quarterly scanning cadence

Embed mandatory equity variant in all scenario packs

Introduce structured capability review every academic year

Develop staff development on AI-supported strategic synthesis

Reduce over-reliance on polished AI summaries without deep interrogation

AI use statement (draft):
Artificial intelligence tools were used to support structured environmental scanning, trend clustering, and first-draft scenario development within the institutional foresight cycle. All AI outputs were treated as advisory drafts and subject to documented human review, challenge, and revision prior to any strategic decision. Human decision-makers retained full authority over interpretation, prioritisation, and approval. AI contributions were transparently recorded to support auditability and governance oversight.

Task:
1) For each listed activity, reconstruct (a) assumptions/scenarios used; (b) decisions made; (c) what subsequently happened; include at least 2 context-specific examples.
2) Identify what was overestimated or underestimated and how AI tools helped or hindered judgement and learning.
3) Produce 6–10 “Design Principles for Future Foresight Work” that embed scheduled updates, equity checks, and documentation.
4) Provide a structured capability_map summary across the six domains and draft a neutral 2–4 sentence AI_use_statement suitable for attaching to governance records.

Treat outputs as draft options for human review.

Return using headings:
A) Draft Output
B) Assumptions
C) Risks / Uncertainties (at least 3)
D) Validation Checks (at least 3)
E) Questions for Human Review

