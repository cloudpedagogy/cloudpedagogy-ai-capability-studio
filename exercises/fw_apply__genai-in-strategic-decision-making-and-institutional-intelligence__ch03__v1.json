{
  "schema_version": "1.0",
  "id": "fw_apply__genai-in-strategic-decision-making-and-institutional-intelligence__ch03__v1",
  "title": "Apply the AI Capability Framework — AI Tools for Real-Time Environmental Scanning (Foresight Cycle)",
  "template": "structured_workflow",
  "version": "1.0",
  "status": "active",
  "source": "imported",
  "tags": [
    "framework:apply",
    "topic:foresight",
    "topic:environmental-scanning",
    "topic:scenario-planning",
    "topic:stress-testing",
    "context:higher-education",
    "course:genai-in-strategic-decision-making-and-institutional-intelligence",
    "chapter:ch03"
  ],
  "summary": "Apply the CloudPedagogy AI Capability Framework (2026) to design, run, and govern an AI-augmented foresight cycle—from environmental scanning to scenario building, stress-testing, and operational translation.",
  "estimated_time_minutes": 90,
  "recommended_ai_tools": [
    "ChatGPT",
    "Claude",
    "Gemini",
    "Perplexity"
  ],
  "difficulty_level": "intermediate",
  "audience": "Higher education strategy teams, governance leads, digital education leaders, academic leaders, and planning offices",
  "design_intent": "Support responsible AI-augmented institutional foresight without techno-solutionism by making assumptions explicit, separating drafting from judgement, documenting decision pathways, and embedding equity and accountability across scanning, scenarios, simulations, and operational translation.",
  "pedagogical_focus": "Structured human–AI collaboration across the six AI Capability Framework domains to produce governance-ready foresight artefacts (orientation note, co-agency charter, scanning/trend prototypes, ethical futures audit, decision log, learning log). Guardrails: anonymise data; treat AI outputs as draft; do not invent policies; state uncertainty; maintain human accountability.",
  "inputs_required": [
    {
      "key": "context_type",
      "type": "select",
      "required": true,
      "options": [
        "institutional_strategy",
        "governance_committee",
        "faculty_planning",
        "programme_design",
        "research_planning",
        "public_policy_service"
      ]
    },
    {
      "key": "field_area",
      "type": "text",
      "required": true
    },
    {
      "key": "level_scope",
      "type": "select",
      "required": true,
      "options": [
        "introductory",
        "intermediate",
        "advanced",
        "programme_level",
        "institution_level",
        "cross_institution"
      ]
    },
    {
      "key": "notes_priorities",
      "type": "textarea",
      "required": false
    },
    {
      "key": "source_material",
      "type": "textarea",
      "required": true
    }
  ],
  "workflow": {
    "summary": "Move from sensing change to making sense, rehearsing futures, testing vulnerabilities, and translating insights into accountable operational decisions using structured human–AI collaboration.",
    "values": [
      "transparency",
      "stewardship",
      "inclusion",
      "accountability",
      "learning_by_doing"
    ]
  },
  "steps": [
    {
      "step_id": "s1",
      "title": "AI orientation note for your foresight set-up",
      "domain": "Awareness & Orientation",
      "instructions": [
        "Map where AI currently supports scanning, trend analysis, scenario work, or stress-testing in your context.",
        "State assumptions about sources, language, geography, and sector focus that may shape what the model notices.",
        "Identify likely blind spots and missing voices, including marginalised learner and staff perspectives.",
        "Draft an orientation note with strengths, red lines, and a short health warning to attach to AI-generated briefs."
      ],
      "values_in_play": [
        "transparency",
        "humility",
        "stewardship",
        "inclusion"
      ],
      "reflection_prompts": [
        "What do leaders currently believe the model is doing, and where might that mental model be inaccurate?",
        "How could misread confidence in AI summaries distort perceived urgency, risk, or opportunity?"
      ],
      "fields": [
        {
          "key": "current_ai_uses",
          "label": "Current or planned AI uses in foresight",
          "type": "textarea",
          "required": true,
          "placeholder": "List your AI-supported activities (e.g., weekly briefs, scanning automation, trend clustering)."
        },
        {
          "key": "assumptions_and_blind_spots",
          "label": "Assumptions and blind spots",
          "type": "textarea",
          "required": true,
          "placeholder": "Note assumptions (sources, language, geography) and what voices/signals may be missing."
        },
        {
          "key": "orientation_note_requirements",
          "label": "Orientation note requirements",
          "type": "textarea",
          "required": false,
          "placeholder": "Any local red lines, required disclaimers, or governance constraints to include."
        }
      ],
      "prompt_block": {
        "title": "Draft an AI Orientation Note for AI-augmented foresight",
        "prompt_template": "You are supporting the creation of an AI Orientation Note for an AI-augmented institutional foresight workflow (environmental scanning → trends → scenarios → stress-testing → operational translation).\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nCurrent AI uses:\n{{current_ai_uses}}\n\nAssumptions and blind spots:\n{{assumptions_and_blind_spots}}\n\nOrientation note requirements:\n{{orientation_note_requirements}}\n\nTask:\n1) Summarise what the AI system is (and is not) doing in this foresight workflow, in plain language suitable for senior leadership.\n2) List key strengths and key limitations grounded in the provided context (include at least 2 concrete examples of “what it can help with” and “where it can mislead”).\n3) Identify likely missing signals/voices and why (include at least one example relevant to equity, accessibility, Global South perspectives, or non-dominant disciplines).\n4) Produce a one-page AI Orientation Note with: (a) purpose; (b) allowed use cases; (c) red lines; (d) confidence guidance; (e) a 2–3 sentence “health warning” to attach to every AI-generated brief.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties (at least 3)\nD) Validation Checks (at least 3)\nE) Questions for Human Review\n"
      }
    },
    {
      "step_id": "s2",
      "title": "Co-agency charter for scenario and simulation work",
      "domain": "Human–AI Co-Agency",
      "instructions": [
        "Define what AI is responsible for in your foresight workflow and what must remain human-led judgement.",
        "Specify review roles, escalation paths, and how disagreements between AI output and human judgement are handled.",
        "Create collaboration patterns for at least two settings relevant to your context (e.g., executive retreat, faculty workshop).",
        "Record accountability statements that make ownership of decisions explicit."
      ],
      "values_in_play": [
        "collaboration",
        "agency",
        "role_clarity",
        "accountability"
      ],
      "reflection_prompts": [
        "Where might AI be overstepping into decisions that should remain human?",
        "Where are humans doing repetitive synthesis that could be safely delegated to AI?"
      ],
      "fields": [
        {
          "key": "ai_responsibilities",
          "label": "What AI is responsible for",
          "type": "textarea",
          "required": true,
          "placeholder": "List tasks AI may do (e.g., first-draft scenarios, clustering themes, drafting personas)."
        },
        {
          "key": "human_responsibilities",
          "label": "What humans are responsible for",
          "type": "textarea",
          "required": true,
          "placeholder": "List human responsibilities (e.g., value framing, plausibility judgement, equity risk review)."
        },
        {
          "key": "collaboration_patterns",
          "label": "Collaboration patterns to design",
          "type": "textarea",
          "required": false,
          "placeholder": "Name 2–3 settings (e.g., executive retreat, committee cycle) and any constraints."
        }
      ],
      "prompt_block": {
        "title": "Draft a Co-Agency Charter for AI-supported foresight",
        "prompt_template": "You are supporting the design of a Co-Agency Charter that clarifies human vs AI roles in scenario planning, simulation, and synthesis within an institutional foresight cycle.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nAI responsibilities:\n{{ai_responsibilities}}\n\nHuman responsibilities:\n{{human_responsibilities}}\n\nCollaboration patterns to design:\n{{collaboration_patterns}}\n\nTask:\n1) Draft a Co-Agency Charter with clear role boundaries: what AI may draft, what humans must decide, and what requires joint review.\n2) Define review checkpoints (who reviews, when, and what criteria trigger revision or rejection), with at least 2 context-specific examples.\n3) Specify a disagreement protocol: how to handle conflicts between AI outputs and human judgement (include escalation and documentation).\n4) Produce 2–3 collaboration patterns (e.g., executive retreat, faculty foresight workshop, operational risk meeting) showing when AI is used, who reviews outputs, and how decisions are recorded.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties (at least 3)\nD) Validation Checks (at least 3)\nE) Questions for Human Review\n"
      }
    },
    {
      "step_id": "s3",
      "title": "Prototype an AI-enabled scanning and trend workflow",
      "domain": "Generative Practice & Innovation",
      "instructions": [
        "Sketch a minimal viable workflow for scanning and trend analysis including sources, prompts, review points, and output cadence.",
        "Generate 3–4 scanning lenses tailored to your context and produce contrasting brief variants per lens.",
        "Select one micro-innovation to pilot and define success criteria, ownership, and retirement triggers.",
        "Ensure the prototype is realistic for busy institutional conditions and aligned with local governance."
      ],
      "values_in_play": [
        "creative_risk_taking",
        "proportionality",
        "inclusion",
        "learning_by_doing"
      ],
      "reflection_prompts": [
        "How can AI-enabled scanning avoid becoming glossy output without operational follow-through?",
        "Which experiments are safe to run immediately, and which require formal approval?"
      ],
      "fields": [
        {
          "key": "candidate_sources",
          "label": "Candidate sources and signals",
          "type": "textarea",
          "required": true,
          "placeholder": "List sources (policy portals, sector news, funders, internal data) and what you aim to detect."
        },
        {
          "key": "prototype_workflow_constraints",
          "label": "Workflow constraints and review points",
          "type": "textarea",
          "required": true,
          "placeholder": "Note cadence, reviewers, risk tolerance, and any tools you expect to use (optional)."
        },
        {
          "key": "pilot_micro_innovation",
          "label": "Micro-innovation to pilot",
          "type": "textarea",
          "required": false,
          "placeholder": "Describe one pilot (e.g., fortnightly Trend Pulse) and what success would look like."
        }
      ],
      "prompt_block": {
        "title": "Design a minimal viable AI-enabled scanning + trend analysis workflow",
        "prompt_template": "You are supporting the prototyping of an AI-enabled environmental scanning and trend analysis workflow that is small enough to pilot but robust enough for governance use.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nCandidate sources and signals:\n{{candidate_sources}}\n\nWorkflow constraints and review points:\n{{prototype_workflow_constraints}}\n\nMicro-innovation to pilot:\n{{pilot_micro_innovation}}\n\nTask:\n1) Propose a minimal viable workflow (inputs → processing → review → outputs) including sources, prompt strategy, review checkpoints, and output cadence.\n2) Propose 3–4 novel scanning lenses tailored to this context, and for each lens generate three brief variants (optimistic, pessimistic, equity-focused) with at least 2 context-specific examples of implications.\n3) Recommend one micro-innovation to pilot, including ownership, success criteria, and a “stop/retire” trigger if outputs are misleading or harmful.\n4) List practical constraints and mitigations (time, capability, governance) to keep the prototype realistic.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties (at least 3)\nD) Validation Checks (at least 3)\nE) Questions for Human Review\n"
      }
    },
    {
      "step_id": "s4",
      "title": "Ethical futures audit of scenarios and simulations",
      "domain": "Ethics, Equity & Impact",
      "instructions": [
        "Select one scenario output and identify who is explicit, implicit, and absent across learners, staff, partners, and regions.",
        "Generate an equity-anchored variant that centres a minoritised group or justice perspective.",
        "Compare strategic conclusions that follow from the original and the equity-anchored variant.",
        "Define a repeatable rule for ensuring every scenario pack includes at least one equity-anchored variant."
      ],
      "values_in_play": [
        "equity",
        "justice",
        "accessibility",
        "epistemic_plurality"
      ],
      "reflection_prompts": [
        "What harms arise when leadership only sees futures centred on dominant groups or well-resourced institutions?",
        "How could you institutionalise equity-anchored variants as a non-optional practice?"
      ],
      "fields": [
        {
          "key": "scenario_to_audit",
          "label": "Scenario to audit",
          "type": "textarea",
          "required": true,
          "placeholder": "Paste or describe the scenario you want to audit (or summarise key elements)."
        },
        {
          "key": "missing_voices_checklist",
          "label": "Who is missing or marginalised",
          "type": "textarea",
          "required": true,
          "placeholder": "List groups/regions/disciplines likely to be absent (e.g., disabled learners, Global South partners)."
        },
        {
          "key": "equity_focus",
          "label": "Equity focus for the alternative scenario",
          "type": "textarea",
          "required": false,
          "placeholder": "Name the perspective to centre (e.g., accessibility, decolonial, carers, distance learners)."
        }
      ],
      "prompt_block": {
        "title": "Run an Ethical Futures Audit and generate an equity-anchored scenario variant",
        "prompt_template": "You are supporting an Ethical Futures Audit of AI-generated scenarios to identify bias, blind spots, and equity impacts.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nScenario to audit:\n{{scenario_to_audit}}\n\nWho is missing or marginalised:\n{{missing_voices_checklist}}\n\nEquity focus for the alternative scenario:\n{{equity_focus}}\n\nTask:\n1) Audit the scenario by identifying who appears explicitly, implicitly, and who is absent; include at least 2 context-specific examples of how absence could distort decisions.\n2) Generate an alternative version of the same scenario that centres the specified equity focus (or propose a suitable equity focus if not provided).\n3) Compare the original and equity-anchored scenarios and list 3 ways strategic conclusions, risks, or priorities might differ.\n4) Propose a simple, repeatable institutional rule for equity-anchored variants (e.g., “every scenario pack must include one equity variant + one Global South variant”) and how it would be checked.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties (at least 3)\nD) Validation Checks (at least 3)\nE) Questions for Human Review\n"
      }
    },
    {
      "step_id": "s5",
      "title": "Governance design for AI-supported foresight decisions",
      "domain": "Decision-Making & Governance",
      "instructions": [
        "Map one decision pathway where AI informs scanning, trends, scenarios, stress-testing, and operational planning.",
        "Define where AI is used, who can override outputs, and what documentation is mandatory at each stage.",
        "Draft a foresight decision log template capturing options tested, equity implications, and final justification.",
        "Identify who gains influence through AI-supported foresight and design participation checks to reduce marginalisation."
      ],
      "values_in_play": [
        "transparency",
        "accountability",
        "participation",
        "stewardship"
      ],
      "reflection_prompts": [
        "Who gains influence from AI-supported foresight in your current structures, and who risks being sidelined?",
        "How can transparent logs and participatory review reduce the risk of 'AI-washed' decisions?"
      ],
      "fields": [
        {
          "key": "decision_question",
          "label": "Decision question to map",
          "type": "textarea",
          "required": true,
          "placeholder": "State a real decision (e.g., invest in AI-enabled student support systems)."
        },
        {
          "key": "decision_pathway_stages",
          "label": "Foresight stages involved",
          "type": "textarea",
          "required": true,
          "placeholder": "Describe stages (scan, trends, scenarios, stress-test, ops plan) and who is involved."
        },
        {
          "key": "governance_constraints",
          "label": "Governance constraints",
          "type": "textarea",
          "required": false,
          "placeholder": "Note required committees, documentation standards, model transparency needs, or policy constraints."
        }
      ],
      "prompt_block": {
        "title": "Design a governance pattern and decision log for AI-supported foresight",
        "prompt_template": "You are supporting the design of a governance pattern for AI-supported institutional foresight that traces how AI outputs influence decisions and documents accountability.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nDecision question to map:\n{{decision_question}}\n\nForesight stages involved:\n{{decision_pathway_stages}}\n\nGovernance constraints:\n{{governance_constraints}}\n\nTask:\n1) Map a decision pathway across scanning, trend analysis, scenario building, stress-testing, and operational translation; describe where AI is used at each stage.\n2) For each stage, specify: (a) who has the right to question/override; (b) what must be documented (prompts, data sources, assumptions, human decisions); include at least 2 context-specific examples.\n3) Draft a “Foresight Decision Log” template with fields for options tested, futures/scenarios considered, equity implications, and final justification.\n4) Identify participation risks (who is marginalised) and propose safeguards (e.g., cross-unit review, student/community voice, equity gate).\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties (at least 3)\nD) Validation Checks (at least 3)\nE) Questions for Human Review\n"
      }
    },
    {
      "step_id": "s6",
      "title": "Foresight learning log and capability renewal",
      "domain": "Reflection, Learning & Renewal",
      "instructions": [
        "Reconstruct 2–3 foresight activities and record assumptions, decisions, and what actually happened over time.",
        "Identify what was overestimated or underestimated and how AI tools helped or hindered sense-making.",
        "Extract repeatable design principles for future foresight work including scheduled updates and equity checks.",
        "Write an AI use statement suitable for governance documentation and future audit trails."
      ],
      "values_in_play": [
        "learning",
        "humility",
        "renewal",
        "continuity"
      ],
      "reflection_prompts": [
        "If you looked back in five years, what would you want recorded about how AI shaped foresight today?",
        "How can foresight become cumulative capability rather than disconnected projects?"
      ],
      "fields": [
        {
          "key": "past_foresight_activities",
          "label": "Past or current foresight activities to log",
          "type": "textarea",
          "required": true,
          "placeholder": "List 2–3 activities (e.g., COVID-era scenarios, AI assessment futures, digital resilience stress-test)."
        },
        {
          "key": "capability_map",
          "label": "Capability map / renewal summary",
          "type": "textarea",
          "required": true,
          "placeholder": "Summarise what capability improved across the six domains and what needs renewal next."
        },
        {
          "key": "ai_use_statement",
          "label": "AI use statement (for governance)",
          "type": "textarea",
          "required": false,
          "placeholder": "2–4 neutral sentences describing how AI was used and what human checks were applied."
        }
      ],
      "prompt_block": {
        "title": "Create a foresight learning log, capability map, and AI use statement",
        "prompt_template": "You are supporting a Foresight Learning Log that turns repeated scanning/scenario activities into cumulative organisational learning and a governance-ready capability record.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nPast or current foresight activities to log:\n{{past_foresight_activities}}\n\nCapability map / renewal summary:\n{{capability_map}}\n\nAI use statement (draft):\n{{ai_use_statement}}\n\nTask:\n1) For each listed activity, reconstruct (a) assumptions/scenarios used; (b) decisions made; (c) what subsequently happened; include at least 2 context-specific examples.\n2) Identify what was overestimated or underestimated and how AI tools helped or hindered judgement and learning.\n3) Produce 6–10 “Design Principles for Future Foresight Work” that embed scheduled updates, equity checks, and documentation.\n4) Provide a structured capability_map summary across the six domains and draft a neutral 2–4 sentence AI_use_statement suitable for attaching to governance records.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties (at least 3)\nD) Validation Checks (at least 3)\nE) Questions for Human Review\n"
      }
    }
  ],
  "export": {
    "record_title": "AI Workflow Record",
    "record_subtitle": "Structured AI Practice Log",
    "recommended_filename_slug": "fw_apply__genai-in-strategic-decision-making-and-institutional-intelligence__ch03__v1",
    "sections": [
      "metadata",
      "inputs",
      "step_responses",
      "generated_prompts",
      "ai_outputs_raw",
      "human_revisions",
      "checks_snapshot",
      "ai_use_statement"
    ],
    "agent_ready_payload": {
      "workflow_kind": "framework_application",
      "version": "1.0",
      "fields": []
    }
  }
}