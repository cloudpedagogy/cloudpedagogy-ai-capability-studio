{
  "schema_version": "1.0",
  "id": "pt_apply__genai-in-strategic-decision-making-and-institutional-intelligence__ch03__ls01__v1",
  "title": "Prompt Templates — Environmental Scanning & Scenario Planning (Lesson 1)",
  "template": "structured_workflow",
  "version": "1.0",
  "status": "active",
  "source": "imported",
  "tags": [
    "type:prompt-templates",
    "topic:environmental-scanning",
    "topic:trend-analysis",
    "topic:scenario-planning",
    "topic:foresight-to-operations",
    "id_prefix:pt_apply",
    "lesson:ls01",
    "chapter:ch03"
  ],
  "summary": "Turn a lesson’s Prompt Templates into a reusable, context-aware prompt set for environmental scanning, trend synthesis, scenario building, and foresight-to-operations alignment.",
  "estimated_time_minutes": 50,
  "difficulty_level": "intermediate",
  "audience": "higher_education_strategy_and_governance",
  "design_intent": "Help users adapt and quality-check strategic prompt templates so outputs are structured, context-specific, and governance-safe.",
  "inputs_required": [
    {
      "key": "context_type",
      "label": "Context type",
      "type": "select",
      "required": true,
      "options": [
        "Higher education (university)",
        "Further education / college",
        "Research institute",
        "Public sector",
        "Other"
      ]
    },
    {
      "key": "field_area",
      "label": "Field / discipline or domain focus",
      "type": "text",
      "required": true
    },
    {
      "key": "level_scope",
      "label": "Level / scope",
      "type": "select",
      "required": true,
      "options": [
        "Institution-wide",
        "Faculty / school",
        "Department / unit",
        "Programme / curriculum",
        "Project / initiative"
      ]
    },
    {
      "key": "notes_priorities",
      "label": "Priorities / constraints (optional)",
      "type": "textarea",
      "required": false
    },
    {
      "key": "source_material",
      "label": "Source material (paste notes, links, headlines, or evidence snippets)",
      "type": "textarea",
      "required": true
    }
  ],
  "workflow": {
    "summary": "Select and adapt prompt templates, enrich with local context, and run a structured quality cycle so outputs can be used safely in strategic planning and governance conversations.",
    "values": [
      "clarity",
      "specificity",
      "accountability",
      "equity_awareness",
      "verification"
    ]
  },
  "steps": [
    {
      "step_id": "s1",
      "title": "Prompt Analysis",
      "domain": "Awareness & Orientation",
      "instructions": [
        "Identify which prompt template types you need for this task (scan, trends, scenarios, alignment).",
        "Extract the key constraints the prompt must respect (audience, scope, timeframe, evidence expectations).",
        "Decide what “good output” looks like in your context (format, length, decision-use).",
        "Note likely failure modes (generic answers, invented facts, missing HE specificity)."
      ],
      "values_in_play": [
        "clarity",
        "fitness_for_purpose",
        "context_sensitivity"
      ],
      "reflection_prompts": [
        "What decisions will this output inform, and what would make it unusable?",
        "Which parts must be evidence-grounded versus exploratory?"
      ],
      "fields": [
        {
          "key": "chosen_templates",
          "label": "Templates to create (scan / trends / scenarios / alignment)",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., Environmental scan + Trend map + 2x2 scenarios + Ops alignment actions"
        },
        {
          "key": "intended_audience",
          "label": "Intended audience and use",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., Exec team briefing; teaching & learning committee; planning office workshop"
        },
        {
          "key": "output_constraints",
          "label": "Output constraints (length, format, time horizon)",
          "type": "textarea",
          "required": false,
          "placeholder": "e.g., 1 page; table + short narrative; 2035 horizon; bullets only"
        }
      ],
      "prompt_block": {
        "title": "Analyse needs and define success criteria",
        "prompt_template": "You are supporting prompt selection and success-criteria definition for strategic foresight work.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nSelected templates: {{chosen_templates}}\nAudience/use: {{intended_audience}}\nConstraints: {{output_constraints}}\n\nTask:\n1) Define what a high-quality output would look like for each selected template (format + decision-use).\n2) List the minimum context details the prompt must contain to avoid generic outputs.\n3) Identify at least 3 risks/failure modes (e.g., fabrication, overgeneralisation, bias) and how to mitigate.\n4) Provide at least 3 validation checks we can apply after generation.\n5) Give at least 2 context-specific examples of constraints or details we should include.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties\nD) Validation Checks\nE) Questions for Human Review"
      }
    },
    {
      "step_id": "s2",
      "title": "Context Enrichment",
      "domain": "Human–AI Co-Agency",
      "instructions": [
        "Add local institutional characteristics the templates should reflect (mission, size, constraints).",
        "Define what evidence you will and will not allow the AI to infer from the source material.",
        "Specify how you want strong vs weak signals handled (definitions, labels, thresholds).",
        "Set a transparency rule for uncertainty and missing evidence."
      ],
      "values_in_play": [
        "human_accountability",
        "transparency",
        "method_discipline"
      ],
      "reflection_prompts": [
        "Where must humans remain the final interpreters (and why)?",
        "What would be a responsible way to represent uncertainty in outputs?"
      ],
      "fields": [
        {
          "key": "institution_profile",
          "label": "Institution profile (type, mission, notable constraints)",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., mid-sized UK university; global health focus; tight budgets; strong research mission"
        },
        {
          "key": "signal_definitions",
          "label": "Signal rules (strong/weak definitions, categories)",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., strong=confirmed policy/regulatory move; weak=early pilots; categories=policy, funding, tech, students"
        },
        {
          "key": "transparency_rules",
          "label": "Transparency rules (what must be stated explicitly)",
          "type": "textarea",
          "required": false,
          "placeholder": "e.g., cite what comes from sources vs inference; flag missing evidence; no invented policies"
        }
      ],
      "prompt_block": {
        "title": "Enrich prompts with context and transparency rules",
        "prompt_template": "You are supporting context enrichment for a strategic prompt set.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nInstitution profile: {{institution_profile}}\nSignal rules: {{signal_definitions}}\nTransparency rules: {{transparency_rules}}\n\nTask:\n1) Produce context snippets (2–4 lines each) that can be pasted into prompts to tailor outputs to this institution.\n2) Draft a short instruction block that forces explicit uncertainty and avoids invented facts/policies.\n3) Provide at least 3 risks (including bias/blind spots) arising from our source material and context.\n4) Provide at least 3 validation checks that align with our transparency rules.\n5) Give at least 2 context-specific examples of how the institution profile changes prompt wording.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties\nD) Validation Checks\nE) Questions for Human Review"
      }
    },
    {
      "step_id": "s3",
      "title": "Structured Prompt Construction",
      "domain": "Generative Practice & Innovation",
      "instructions": [
        "Draft the final prompt templates you will actually run (scan, trends, scenarios, alignment).",
        "Enforce required structure (sections, tables, counts, and output limits).",
        "Bake in requests for examples, risks, and validation checks.",
        "Ensure prompts are tool-agnostic and suitable for governance contexts."
      ],
      "values_in_play": [
        "specificity",
        "reusability",
        "structure"
      ],
      "reflection_prompts": [
        "Which prompt elements most improved relevance compared to a generic prompt?",
        "What would make these templates reusable across units?"
      ],
      "fields": [
        {
          "key": "scan_prompt",
          "label": "Environmental scan prompt (draft)",
          "type": "textarea",
          "required": true,
          "placeholder": "Draft the scan prompt you want to run (or leave blank to have AI draft it)"
        },
        {
          "key": "scenario_prompt",
          "label": "Scenario matrix prompt (draft)",
          "type": "textarea",
          "required": true,
          "placeholder": "Draft the scenario prompt you want to run (or leave blank to have AI draft it)"
        },
        {
          "key": "alignment_prompt",
          "label": "Foresight-to-operations alignment prompt (draft)",
          "type": "textarea",
          "required": false,
          "placeholder": "Draft an alignment prompt (actions/KPIs/owners) or request AI to draft"
        }
      ],
      "prompt_block": {
        "title": "Generate the final set of runnable prompt templates",
        "prompt_template": "You are supporting construction of runnable, structured prompt templates for strategic foresight work.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nEnvironmental scan prompt (draft or blank): {{scan_prompt}}\nScenario prompt (draft or blank): {{scenario_prompt}}\nAlignment prompt (draft or blank): {{alignment_prompt}}\n\nTask:\n1) Produce 3–4 final prompt templates (scan, trends, scenarios, alignment) that reflect the context and signal rules.\n2) Each template must demand: at least 2 context-specific examples, at least 3 risks, and at least 3 validation checks.\n3) Ensure each template specifies the output format (sections or table columns) and an output length limit.\n4) Add a short “prompt hygiene” line that prohibits invented facts/policies and forces explicit uncertainty.\n5) Provide at least 3 risks about how these prompts could still fail, plus mitigation.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties\nD) Validation Checks\nE) Questions for Human Review"
      }
    },
    {
      "step_id": "s4",
      "title": "Risk and Bias Review",
      "domain": "Ethics, Equity & Impact",
      "instructions": [
        "Check for bias, over-reliance on dominant sources, and missing perspectives.",
        "Add counter-prompts that explicitly request Global South, non-dominant disciplines, or local community lenses.",
        "Define what must be red-flagged before sharing outputs (harm, exclusion, misrepresentation).",
        "Decide how you will cite or document evidence boundaries."
      ],
      "values_in_play": [
        "equity_awareness",
        "harm_reduction",
        "epistemic_humility"
      ],
      "reflection_prompts": [
        "Who could be disadvantaged by the default data sources used for these prompts?",
        "What counter-practices will you embed to diversify perspectives?"
      ],
      "fields": [
        {
          "key": "bias_risks",
          "label": "Bias and blind-spot risks to watch for",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., Global North dominance; English-only sources; tech-solutionism; neglect of accessibility"
        },
        {
          "key": "diversity_rules",
          "label": "Diversity rules (sources and perspectives to include)",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., include Global South sources; community org reports; student union perspectives; non-dominant disciplines"
        },
        {
          "key": "red_flags",
          "label": "Red flags (when outputs must not be used as-is)",
          "type": "textarea",
          "required": false,
          "placeholder": "e.g., policy claims without evidence; stereotyping; recommendations that bypass governance; unsafe advice"
        }
      ],
      "prompt_block": {
        "title": "Audit the prompt set for bias and equity risks",
        "prompt_template": "You are supporting an ethics and equity audit of strategic prompt templates.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nBias risks: {{bias_risks}}\nDiversity rules: {{diversity_rules}}\nRed flags: {{red_flags}}\n\nTask:\n1) Identify at least 3 ways the prompt set could amplify bias or exclude perspectives, and propose edits.\n2) Draft 2 counter-prompts that explicitly diversify perspective (e.g., Global South, student equity, Indigenous/community lenses).\n3) Provide at least 3 risks and at least 3 validation checks tailored to equity and harm reduction.\n4) Provide at least 2 context-specific examples of how to phrase prompts to avoid deficit narratives.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties\nD) Validation Checks\nE) Questions for Human Review"
      }
    },
    {
      "step_id": "s5",
      "title": "Format and Output Structuring",
      "domain": "Decision-Making & Governance",
      "instructions": [
        "Define the output formats you will share (briefing note, table, slide-ready bullets).",
        "Add governance checks: evidence boundaries, ownership, and decision traceability.",
        "Specify what must be reviewed by humans before circulation.",
        "Create a reusable checklist for future runs."
      ],
      "values_in_play": [
        "traceability",
        "governance",
        "quality_assurance"
      ],
      "reflection_prompts": [
        "What would make this output safe to share with a committee?",
        "What should be recorded as a decision versus a suggestion?"
      ],
      "fields": [
        {
          "key": "share_format",
          "label": "Share format (brief/table/slides) and required sections",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., 1-page brief with policy/tech/funding/students; include strong vs weak signals; add implications"
        },
        {
          "key": "decision_trace",
          "label": "Decision trace needs (who decides, what gets logged)",
          "type": "textarea",
          "required": true,
          "placeholder": "e.g., planning office validates; academic board reviews; log assumptions and sources"
        },
        {
          "key": "governance_checks",
          "label": "Governance checks (pre-circulation)",
          "type": "textarea",
          "required": false,
          "placeholder": "e.g., check for fabricated citations; check equity impacts; confirm scope; confirm confidentiality"
        }
      ],
      "prompt_block": {
        "title": "Convert outputs into governance-safe formats and checks",
        "prompt_template": "You are supporting governance-safe formatting and decision-trace design for strategic AI outputs.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nShare format: {{share_format}}\nDecision trace needs: {{decision_trace}}\nGovernance checks: {{governance_checks}}\n\nTask:\n1) Draft a short reusable format spec (sections/columns) for sharing outputs in this context.\n2) Propose a decision-trace mini-protocol (who reviews what, and what is logged).\n3) Provide at least 3 risks and at least 3 validation checks focused on governance (e.g., evidence boundaries, misinterpretation).\n4) Provide at least 2 context-specific examples of phrasing that signals uncertainty and prevents overclaiming.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties\nD) Validation Checks\nE) Questions for Human Review"
      }
    },
    {
      "step_id": "s6",
      "title": "Reflection and Refinement",
      "domain": "Reflection, Learning & Renewal",
      "instructions": [
        "Record what worked and what failed when running the prompts.",
        "Capture improvements to wording, structure, or evidence expectations.",
        "Decide what you will reuse, retire, or version-up for next time.",
        "Write a short AI-use statement suitable for governance documentation."
      ],
      "values_in_play": [
        "learning",
        "iterative_improvement",
        "responsible_use"
      ],
      "reflection_prompts": [
        "Which edits most improved relevance and reduced risk?",
        "What capability did you strengthen by doing this work?"
      ],
      "fields": [
        {
          "key": "run_notes",
          "label": "Run notes (what happened when you used the prompts)",
          "type": "textarea",
          "required": true,
          "placeholder": "Briefly note outcomes, surprises, and failure modes"
        },
        {
          "key": "prompt_improvements",
          "label": "Prompt improvements to carry forward",
          "type": "textarea",
          "required": true,
          "placeholder": "Specify edits you will make next time and why"
        },
        {
          "key": "ai_use_statement",
          "label": "AI-use statement (for export / governance)",
          "type": "textarea",
          "required": false,
          "placeholder": "2–4 neutral sentences describing how AI was used and how humans validated outputs"
        }
      ],
      "prompt_block": {
        "title": "Reflect, improve, and draft an AI-use statement",
        "prompt_template": "You are supporting reflective refinement of a strategic prompt set after use.\n\nContext type: {{context_type}}\nField/discipline: {{field_area}}\nLevel/scope: {{level_scope}}\nPriorities: {{notes_priorities}}\nSource material: {{source_material}}\n\nRun notes: {{run_notes}}\nPrompt improvements: {{prompt_improvements}}\n\nTask:\n1) Summarise what worked and what failed, focusing on decision-use and governance safety.\n2) Propose a short versioning plan (what changes justify v2, what stays stable).\n3) Provide at least 3 risks and at least 3 validation checks for future runs.\n4) Provide at least 2 context-specific examples of improved prompt wording.\n5) Draft a 2–4 sentence neutral AI-use statement suitable for governance documentation.\n\nTreat outputs as draft options for human review.\n\nReturn using headings:\nA) Draft Output\nB) Assumptions\nC) Risks / Uncertainties\nD) Validation Checks\nE) Questions for Human Review"
      }
    }
  ],
  "export": {
    "record_title": "AI Workflow Record",
    "record_subtitle": "Structured AI Practice Log",
    "recommended_filename_slug": "prompt-templates-environmental-scanning-scenarios",
    "sections": [
      "metadata",
      "inputs",
      "step_responses",
      "generated_prompts",
      "ai_outputs_raw",
      "human_revisions",
      "checks_snapshot"
    ],
    "agent_ready_payload": {
      "workflow_kind": "prompt_template_application",
      "version": "1.0",
      "fields": [
        "context_type",
        "field_area",
        "level_scope",
        "notes_priorities",
        "source_material"
      ]
    }
  }
}